import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

def load_and_preprocess_data(data):
    """
    –ó–∞—Ä–µ–∂–¥–∞ –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª–Ω–æ –æ–±—Ä–∞–±–æ—Ç–≤–∞ Cancer dataset.
    
    Parameters:
    -----------
    data : pandas.DataFrame
        Raw cancer data
        
    Returns:
    --------
    tuple
        (X, y, feature_names, scaler)
        X : array-like, shape (n_samples, n_features) - –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–∞–Ω–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        y : array-like, shape (n_samples,) - –ë–∏–Ω–∞—Ä–Ω–∏ –µ—Ç–∏–∫–µ—Ç–∏ (0/1)
        feature_names : list - –ò–º–µ–Ω–∞ –Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏—Ç–µ
        scaler : StandardScaler - –û–±—É—á–µ–Ω scaler –∑–∞ –¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    """
    
    # –°—ä–∑–¥–∞–≤–∞–º–µ –∫–æ–ø–∏–µ –∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–∞ —Ä–∞–±–æ—Ç–∞
    df = data.copy()
    
    # –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º–µ –∑–∞–¥—ä–ª–∂–∏—Ç–µ–ª–Ω–∏—Ç–µ –∫–æ–ª–æ–Ω–∏
    if 'diagnosis' not in df.columns:
        raise ValueError("Dataset —Ç—Ä—è–±–≤–∞ –¥–∞ —Å—ä–¥—ä—Ä–∂–∞ –∫–æ–ª–æ–Ω–∞ 'diagnosis'")
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–≤–∞–º–µ diagnosis –≤ –±–∏–Ω–∞—Ä–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
    # M (Malignant) = 1, B (Benign) = 0
    diagnosis_map = {'M': 1, 'B': 0}
    y = df['diagnosis'].map(diagnosis_map)
    
    if y.isnull().any():
        raise ValueError("Diagnosis –∫–æ–ª–æ–Ω–∞—Ç–∞ —Å—ä–¥—ä—Ä–∂–∞ –Ω–µ—Ä–∞–∑–ø–æ–∑–Ω–∞—Ç–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏. –û—á–∞–∫–≤–∞—Ç —Å–µ 'M' –∏–ª–∏ 'B'.")
    
    # –ü—Ä–µ–º–∞—Ö–≤–∞–º–µ –Ω–µ—á–∏—Å–ª–æ–≤–∏ –∫–æ–ª–æ–Ω–∏
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    
    # –ü—Ä–µ–º–∞—Ö–≤–∞–º–µ id –∫–æ–ª–æ–Ω–∏ –∞–∫–æ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞—Ç
    id_columns = [col for col in df.columns if 'id' in col.lower()]
    numeric_columns = [col for col in numeric_columns if col not in id_columns]
    
    if len(numeric_columns) == 0:
        raise ValueError("–ù–µ —Å–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ —á–∏—Å–ª–æ–≤–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ dataset-–∞")
    
    # –ò–∑–≤–ª–∏—á–∞–º–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏—Ç–µ
    X = df[numeric_columns].values
    feature_names = list(numeric_columns)
    
    # –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º–µ –∑–∞ –ª–∏–ø—Å–≤–∞—â–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
    if np.isnan(X).any():
        print("‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: –ù–∞–º–µ—Ä–µ–Ω–∏ —Å–∞ –ª–∏–ø—Å–≤–∞—â–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏. –ó–∞–º–µ—Å—Ç–≤–∞—Ç —Å–µ —Å—ä—Å —Å—Ä–µ–¥–Ω–∞—Ç–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç.")
        # –ó–∞–º–µ—Å—Ç–≤–∞–º–µ NaN —Å—ä—Å —Å—Ä–µ–¥–Ω–∞—Ç–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç
        from sklearn.impute import SimpleImputer
        imputer = SimpleImputer(strategy='mean')
        X = imputer.fit_transform(X)
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–∞–º–µ –¥–∞–Ω–Ω–∏—Ç–µ
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    
    print(f"‚úÖ –î–∞–Ω–Ω–∏—Ç–µ —Å–∞ –∑–∞—Ä–µ–¥–µ–Ω–∏ —É—Å–ø–µ—à–Ω–æ:")
    print(f"   - –ó–∞–ø–∏—Å–∏: {X.shape[0]}")
    print(f"   - –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {X.shape[1]}")
    print(f"   - –ó–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ —Å–ª—É—á–∞–∏: {y.sum()} ({y.mean()*100:.1f}%)")
    print(f"   - –î–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ —Å–ª—É—á–∞–∏: {len(y) - y.sum()} ({(1-y.mean())*100:.1f}%)")
    
    return X, y.values, feature_names, scaler

def describe_dataset(data):
    """
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—è –¥–µ—Ç–∞–π–ª–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ dataset-–∞.
    
    Parameters:
    -----------
    data : pandas.DataFrame
        Cancer dataset
        
    Returns:
    --------
    dict
        –†–µ—á–Ω–∏–∫ —Å—ä—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ dataset-–∞
    """
    stats = {}
    
    # –û—Å–Ω–æ–≤–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    stats['shape'] = data.shape
    stats['columns'] = data.columns.tolist()
    stats['dtypes'] = data.dtypes.to_dict()
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ diagnosis
    if 'diagnosis' in data.columns:
        diagnosis_counts = data['diagnosis'].value_counts()
        stats['diagnosis_distribution'] = diagnosis_counts.to_dict()
        stats['class_balance'] = diagnosis_counts / len(data)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ —á–∏—Å–ª–æ–≤–∏—Ç–µ –∫–æ–ª–æ–Ω–∏
    numeric_cols = data.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        stats['numeric_summary'] = data[numeric_cols].describe()
        stats['missing_values'] = data[numeric_cols].isnull().sum().to_dict()
        stats['correlations'] = data[numeric_cols].corr()
    
    return stats

def create_sample_data_explanation():
    """
    –°—ä–∑–¥–∞–≤–∞ –æ–±—è—Å–Ω–µ–Ω–∏–µ –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ç–∞ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ.
    
    Returns:
    --------
    str
        –§–æ—Ä–º–∞—Ç–∏—Ä–∞–Ω —Ç–µ–∫—Å—Ç —Å –æ–±—è—Å–Ω–µ–Ω–∏–µ
    """
    explanation = """
    üìä **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞ Cancer Dataset:**
    
    **–û—Å–Ω–æ–≤–Ω–∏ –∫–æ–ª–æ–Ω–∏:**
    - `diagnosis`: –î–∏–∞–≥–Ω–æ–∑–∞ (M = –ó–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω, B = –î–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω)
    - –ß–∏—Å–ª–æ–≤–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ —Ç—É–º–æ—Ä–∏—Ç–µ:
    
    **–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
    1. **Radius** - –†–∞–¥–∏—É—Å (—Ä–∞–∑—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ü–µ–Ω—Ç—ä—Ä–∞ –¥–æ —Ç–æ—á–∫–∏—Ç–µ –Ω–∞ –ø–µ—Ä–∏–º–µ—Ç—ä—Ä–∞)
    2. **Texture** - –¢–µ–∫—Å—Ç—É—Ä–∞ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –Ω–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏—Ç–µ –≤ —Å–∏–≤–∞—Ç–∞ —Å–∫–∞–ª–∞)
    3. **Perimeter** - –ü–µ—Ä–∏–º–µ—Ç—ä—Ä
    4. **Area** - –ü–ª–æ—â
    5. **Smoothness** - –ì–ª–∞–¥–∫–æ—Å—Ç (–ª–æ–∫–∞–ª–Ω–∞ –≤–∞—Ä–∏–∞—Ü–∏—è –≤ –¥—ä–ª–∂–∏–Ω–∏—Ç–µ –Ω–∞ —Ä–∞–¥–∏—É—Å–∞)
    6. **Compactness** - –ö–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç (–ø–µ—Ä–∏–º–µ—Ç—ä—Ä¬≤ / –ø–ª–æ—â - 1.0)
    7. **Concavity** - –í–¥–ª—ä–±–Ω–∞—Ç–æ—Å—Ç (—Å–µ—Ä–∏–æ–∑–Ω–æ—Å—Ç –Ω–∞ –≤–¥–ª—ä–±–Ω–∞—Ç–∏—Ç–µ —á–∞—Å—Ç–∏ –Ω–∞ –∫–æ–Ω—Ç—É—Ä–∞)
    8. **Concave points** - –í–¥–ª—ä–±–Ω–∞—Ç–∏ —Ç–æ—á–∫–∏ (–±—Ä–æ–π –≤–¥–ª—ä–±–Ω–∞—Ç–∏ —á–∞—Å—Ç–∏ –Ω–∞ –∫–æ–Ω—Ç—É—Ä–∞)
    9. **Symmetry** - –°–∏–º–µ—Ç—Ä–∏—è
    10. **Fractal dimension** - –§—Ä–∞–∫—Ç–∞–ª–Ω–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç
    
    **–ó–∞ –≤—Å—è–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ —Å–µ –∏–∑—á–∏—Å–ª—è–≤–∞—Ç:**
    - Mean (—Å—Ä–µ–¥–Ω–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç)
    - Standard Error (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –≥—Ä–µ—à–∫–∞)
    - Worst (–Ω–∞–π-–ª–æ—à–∞—Ç–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç)
    
    **–û–±—â–æ: 30 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ + diagnosis**
    """
    
    return explanation

def validate_model_performance(y_true, y_pred, y_pred_proba=None):
    """
    –í–∞–ª–∏–¥–∏—Ä–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª–∞ –∏ –≤—Ä—ä—â–∞ –¥–µ—Ç–∞–π–ª–Ω–∏ –º–µ—Ç—Ä–∏–∫–∏.
    
    Parameters:
    -----------
    y_true : array-like
        –ò—Å—Ç–∏–Ω—Å–∫–∏ –µ—Ç–∏–∫–µ—Ç–∏
    y_pred : array-like
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏ –µ—Ç–∏–∫–µ—Ç–∏
    y_pred_proba : array-like, optional
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        
    Returns:
    --------
    dict
        –†–µ—á–Ω–∏–∫ —Å –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç
    """
    from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                                f1_score, confusion_matrix, classification_report,
                                roc_auc_score, roc_curve)
    
    metrics = {}
    
    # –û—Å–Ω–æ–≤–Ω–∏ –º–µ—Ç—Ä–∏–∫–∏
    metrics['accuracy'] = accuracy_score(y_true, y_pred)
    metrics['precision'] = precision_score(y_true, y_pred)
    metrics['recall'] = recall_score(y_true, y_pred)
    metrics['f1_score'] = f1_score(y_true, y_pred)
    
    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    metrics['confusion_matrix'] = cm
    metrics['true_negatives'] = cm[0, 0]
    metrics['false_positives'] = cm[0, 1]
    metrics['false_negatives'] = cm[1, 0]
    metrics['true_positives'] = cm[1, 1]
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç –∏ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–Ω–æ—Å—Ç
    metrics['sensitivity'] = metrics['recall']  # True Positive Rate
    metrics['specificity'] = cm[0, 0] / (cm[0, 0] + cm[0, 1])  # True Negative Rate
    
    # ROC –º–µ—Ç—Ä–∏–∫–∏ –∞–∫–æ —Å–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–µ–Ω–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    if y_pred_proba is not None:
        metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba)
        fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)
        metrics['roc_curve'] = {'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds}
    
    # –ö–ª–∞—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–µ–Ω –æ—Ç—á–µ—Ç
    metrics['classification_report'] = classification_report(y_true, y_pred, output_dict=True)
    
    return metrics

def generate_medical_interpretation(metrics, feature_importance=None):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ.
    
    Parameters:
    -----------
    metrics : dict
        –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç
    feature_importance : dict, optional
        –í–∞–∂–Ω–æ—Å—Ç –Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏—Ç–µ
        
    Returns:
    --------
    str
        –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
    """
    interpretation = f"""
    üè• **–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ:**
    
    **–û–±—â–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:**
    - –¢–æ—á–Ω–æ—Å—Ç: {metrics['accuracy']:.1%} (–ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª–Ω–∏ –¥–∏–∞–≥–Ω–æ–∑–∏)
    - –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–Ω–æ—Å—Ç: {metrics['sensitivity']:.1%} (–ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç–∫—Ä–∏—Ç–∏ –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ —Å–ª—É—á–∞–∏)
    - –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç: {metrics['specificity']:.1%} (–ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª–Ω–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–∞–Ω–∏ –¥–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ —Å–ª—É—á–∞–∏)
    
    **–ö–ª–∏–Ω–∏—á–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ:**
    - True Positives: {metrics['true_positives']} (–ø—Ä–∞–≤–∏–ª–Ω–æ –æ—Ç–∫—Ä–∏—Ç–∏ –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏)
    - False Negatives: {metrics['false_negatives']} (–ø—Ä–æ–ø—É—Å–Ω–∞—Ç–∏ –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ - –û–ü–ê–°–ù–û!)
    - False Positives: {metrics['false_positives']} (–ø–æ–≥—Ä–µ—à–Ω–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ü–∏—Ä–∞–Ω–∏ –∫–∞—Ç–æ –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏)
    - True Negatives: {metrics['true_negatives']} (–ø—Ä–∞–≤–∏–ª–Ω–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–∞–Ω–∏ –¥–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏)
    
    **–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏ —Å—ä–≤–µ—Ç–∏:**
    """
    
    # –°—ä–≤–µ—Ç–∏ –±–∞–∑–∏—Ä–∞–Ω–∏ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
    if metrics['sensitivity'] < 0.9:
        interpretation += "\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–∏—Å–∫–∞ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–Ω–æ—Å—Ç! –ú–æ–¥–µ–ª—ä—Ç –º–æ–∂–µ –¥–∞ –ø—Ä–æ–ø—É—Å–Ω–µ –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ —Å–ª—É—á–∞–∏."
    
    if metrics['specificity'] < 0.8:
        interpretation += "\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–∏—Å–∫–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç! –ú–Ω–æ–≥–æ –¥–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ —Å–ª—É—á–∞–∏ —Å–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ü–∏—Ä–∞—Ç –∫–∞—Ç–æ –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏."
    
    if metrics['false_negatives'] > 0:
        interpretation += f"\nüî¥ –ö—Ä–∏—Ç–∏—á–Ω–æ: {metrics['false_negatives']} –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ —Å–ª—É—á–∞—è —Å–∞ –ø—Ä–æ–ø—É—Å–Ω–∞—Ç–∏!"
    
    if feature_importance:
        top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:3]
        interpretation += f"\n\n**–ù–∞–π-–≤–∞–∂–Ω–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∑–∞ –¥–∏–∞–≥–Ω–æ–∑–∞—Ç–∞:**"
        for i, (feature, importance) in enumerate(top_features, 1):
            interpretation += f"\n{i}. {feature}: {importance:.4f}"
    
    interpretation += f"""
    
    **–ü—Ä–µ–ø–æ—Ä—ä–∫–∏ –∑–∞ –∫–ª–∏–Ω–∏—á–Ω–æ –∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ:**
    - –ú–æ–¥–µ–ª—ä—Ç —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞ –∫–∞—Ç–æ –ø–æ–º–æ—â–Ω–æ —Å—Ä–µ–¥—Å—Ç–≤–æ, –Ω–µ –∫–∞—Ç–æ –∑–∞–º—è–Ω–∞ –Ω–∞ –ª–µ–∫–∞—Ä—è
    - –ü—Ä–∏ —Å—ä–º–Ω–µ–Ω–∏–µ –≤–∏–Ω–∞–≥–∏ –¥–∞ —Å–µ –ø—Ä–∞–≤–∏ –¥–æ–ø—ä–ª–Ω–∏—Ç–µ–ª–Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
    - –†–µ–¥–æ–≤–Ω–æ –¥–∞ —Å–µ –∞–∫—Ç—É–∞–ª–∏–∑–∏—Ä–∞ —Å –Ω–æ–≤–∏ –¥–∞–Ω–Ω–∏
    """
    
    return interpretation
